{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93745523",
   "metadata": {},
   "source": [
    "# Train-Test Splitting in Machine Learning\n",
    "#### This notebook contains my notes following tutorials from the machinelearningmastery.com website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0990b4eb",
   "metadata": {},
   "source": [
    "- Train-test split is a technique used to evaluate the performance of a machine learning model/algorithm. \n",
    "\n",
    "- It can be used for both classification and regression algorithms. \n",
    "\n",
    "- Involves dividing the datasets into two subsets.\n",
    "\n",
    "    - The first subset is used to fit (or train) the model and is usually called the **training** dataset\n",
    "    \n",
    "    - The second subset is used to evaluate the performance (fit) of the machine learning model. This dataset is often called the **test** dataset. The test dataset is not used for training the model and is kept aside for testing after training the model. In this sence, the **test** dataset has not been seen by the model.\n",
    "    - The performance of the model on the test set can provide a sense of the performance of the model on unseen datasets.\n",
    "    \n",
    "- This technique is useful when there is enough dataset. It should not be used if the data size is small.\n",
    "\n",
    "- With insufficient data, the k-fold cross-validation technique can be used where k-1 folds is used for training the model and 1 fold is used for testing the model.\n",
    "\n",
    "- Train-test split also improves computational efficiency due to working with smaller datasets. \n",
    "\n",
    "- The train-test split is determined by the test_size parameter which determines the proportion of datasets that are assigned to the training and test sets. \n",
    "\n",
    "### How to a choose a test_size split\n",
    "- Computational cost of training the model\n",
    "- Computational cost in evaluating the model\n",
    "- Training test representativeness (consistent target distribution with original dataset)\n",
    "- Test set representativeness (consistent target distribution with original dataset)\n",
    "\n",
    "Common split percentages are:\n",
    "- Train: 80%, Test: 20%\n",
    "- Train: 67%, Test: 33%\n",
    "- Train: 50%, Test: 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e254e791",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffcbc156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(670, 2) (330, 2) (670,) (330,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create the dataset\n",
    "X, y = make_blobs(n_samples=1000)\n",
    "\n",
    "# Split the data into traiing and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "# We can also use train_size argument to split the dataset\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.67)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb888d6f",
   "metadata": {},
   "source": [
    "### Repeatable Train-Test Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd6cdcc",
   "metadata": {},
   "source": [
    "When comparing ML algorithms, it is sometimes required that they are fit and tested on the same datasets. This can be achieved by fixing the seed of the pseudo-random number during the call. Specifically, we set the random_state parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9732f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.55668015 -2.25799207]\n",
      " [ 0.90040631 -2.15669713]\n",
      " [ 8.58794766 -7.78255649]\n",
      " [-4.43181295 -5.09644906]\n",
      " [-3.11308548 -5.35597826]]\n",
      "[[-3.55668015 -2.25799207]\n",
      " [ 0.90040631 -2.15669713]\n",
      " [ 8.58794766 -7.78255649]\n",
      " [-4.43181295 -5.09644906]\n",
      " [-3.11308548 -5.35597826]]\n"
     ]
    }
   ],
   "source": [
    "# demonstrate that the train-test split procedure is repeatable\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create dataset\n",
    "X, y = make_blobs(n_samples=100)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize first 5 rows\n",
    "print(X_train[:5, :])\n",
    "# split again, and we should see the same split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# summarize first 5 rows\n",
    "print(X_train[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d2ba7",
   "metadata": {},
   "source": [
    "### Stratified Train-Test Splits\n",
    "\n",
    "- applicable to classification problems only\n",
    "\n",
    "- some problems do not have balanced number of examples for each class label. \n",
    "\n",
    "- therefore, it is desirable to split the datasets into train and test sets in a way that preserves the same proportions of examples in each class as observed in the original dataset\n",
    "\n",
    "- this is called stratified train-test split.\n",
    "\n",
    "- a stratified train-test split is achieved by setting the 'stratify' argument to the y component of the original dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c4cca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 94, 1: 6})\n",
      "Counter({0: 45, 1: 5})\n",
      "Counter({0: 49, 1: 1})\n"
     ]
    }
   ],
   "source": [
    "# split imbalanced dataset into train and test sets without stratification\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=100, weights=[0.94], flip_y=0, random_state=1)\n",
    "print(Counter(y))\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1)\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc276f9",
   "metadata": {},
   "source": [
    "- In the above, the composition of the train and test sets differ\n",
    "- the original data has a 94% vs 6% clas label distribution\n",
    "- after splitting, the train data contains 45/5 examples and test contains 49/1 examples.\n",
    "- this composition of the train and test sets differ and is not desirable\n",
    "\n",
    "This issue is fixed using the train-test split with stratify option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "835ccd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 94, 1: 6})\n",
      "Counter({0: 47, 1: 3})\n",
      "Counter({0: 47, 1: 3})\n"
     ]
    }
   ],
   "source": [
    "# split imbalanced dataset into train and test sets with stratification\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create dataset\n",
    "X, y = make_classification(n_samples=100, weights=[0.94], flip_y=0, random_state=1)\n",
    "print(Counter(y))\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.50, random_state=1, stratify=y)\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ca2c26",
   "metadata": {},
   "source": [
    "Give that we have a 50% split of the train and test sets, we would expect both the train and test sets to have 47/3 exampes in the train/test sets respectively. We see this is the case as shown above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d49eb0",
   "metadata": {},
   "source": [
    "## Classification Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce6b384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60) (208,)\n",
      "(139, 60) (69, 60) (139,) (69,)\n",
      "Accuracy: 0.783\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/sonar.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "data = dataframe.values\n",
    "# split into inputs and outputs\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# fit the model\n",
    "model = RandomForestClassifier(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafb7ba2",
   "metadata": {},
   "source": [
    "## Regression Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93d014a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "(339, 13) (167, 13) (339,) (167,)\n",
      "MAE: 2.171 (thousands of dollars)\n"
     ]
    }
   ],
   "source": [
    "# train-test split evaluation random forest on the housing dataset\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# load dataset\n",
    "url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'\n",
    "dataframe = read_csv(url, header=None)\n",
    "data = dataframe.values\n",
    "# split into inputs and outputs\n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "print(X.shape, y.shape)\n",
    "# split into train test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "# fit the model\n",
    "model = RandomForestRegressor(random_state=1)\n",
    "model.fit(X_train, y_train)\n",
    "# make predictions\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print('MAE: %.3f (thousands of dollars)' % mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml_pocket_reference] *",
   "language": "python",
   "name": "conda-env-ml_pocket_reference-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
